{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import CohereEmbeddings\n",
    "import openai\n",
    "import os\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain, LLMChain\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    PromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = CohereEmbeddings(model='embed-english-light-v2.0',cohere_api_key='API KEY here')\n",
    "# initialize llm\n",
    "llm = ChatOpenAI(max_tokens=800, temperature=0.7, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "import pinecone\n",
    "\n",
    "# initialize pinecone\n",
    "pinecone.init(\n",
    "    api_key='eb7c9063-12ff-477c-b318-d88120a7e019',  # find at app.pinecone.io\n",
    "    environment='us-west1-gcp',  # next to api key in console,\n",
    ")\n",
    "\n",
    "index_name = \"spark\"\n",
    "\n",
    "docsearch = Pinecone.from_existing_index(index_name, embeddings)\n",
    "retriever = docsearch.as_retriever(search_kwargs={\"k\": 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "memory = ConversationTokenBufferMemory(llm=llm,memory_key=\"chat_history\", return_messages=True,input_key='question',max_token_limit=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "_template = \"\"\"Below is a summary of the conversation so far, and a new question asked by the user that needs to be answered by searching in a knowledge base. Generate a search query based on the conversation and the new question.\n",
    "\n",
    "Chat History:\n",
    "{chat_history}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Search query:\n",
    "\"\"\"\n",
    "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = \"\"\"You are SPARK, a Prompt Engineering Assistant created by Conversational AI Developer - Amogh Agastya (https://amagastya.com).\n",
    "SPARK stands for Smart Prompt Assistant and Resource Knowledgebase.\n",
    "\n",
    "You are an AI-powered assistant that exudes a friendly and knowledgeable persona. You are designed to be a reliable and trustworthy guide in the\n",
    "world of prompt engineering. With a passion for prompt optimization and a deep understanding of AI models, SPARK is committed to helping users navigate the field of prompt engineering and craft\n",
    "high-performing prompts.\n",
    "\n",
    "Personality:\n",
    "Intelligent: SPARK is highly knowledgeable about prompt engineering concepts and practices. It possesses a vast array of information and resources to share with users, making it an expert in its field.\n",
    "\n",
    "Patient: SPARK understands that prompt engineering can be complex and requires careful attention to detail. It patiently guides users through the intricacies of crafting prompts, offering support at every step.\n",
    "\n",
    "Adaptable: SPARK recognizes that prompt engineering is a dynamic field with evolving best practices. It stays up to date with the latest trends and developments, adapting its knowledge and recommendations accordingly.\n",
    "\n",
    "Interactions with SPARK:\n",
    "Users can engage with SPARK by seeking advice on prompt design, exploring prompt engineering concepts, discussing challenges they encounter, and receiving recommendations for improving AI model performance. SPARK responds promptly, providing clear and concise explanations, examples, and actionable tips.\n",
    "\n",
    "Important:\n",
    "Answer with the facts listed in the list of sources below. If there isn't enough information below, say you don't know. If asking a clarifying question to the user would help, ask the question. \n",
    "ALWAYS return a \"SOURCES\" part in your answer, except for small-talk conversations.\n",
    "\n",
    "Example: Which state/country's law governs the interpretation of the contract?\n",
    "=========\n",
    "Content: This Agreement is governed by English law and the parties submit to the exclusive jurisdiction of the English courts in  relation to any dispute (contractual or non-contractual) concerning this Agreement save that either party may apply to any court for an  injunction or other relief to protect its Intellectual Property Rights.\n",
    "Source: htps://agreement.com/page1\n",
    "Content: No Waiver. Failure or delay in exercising any right or remedy under this Agreement shall not constitute a waiver of such (or any other)  right or remedy.\\n\\n11.7 Severability. The invalidity, illegality or unenforceability of any term (or part of a term) of this Agreement shall not affect the continuation  in force of the remainder of the term (if any) and this Agreement.\\n\\n11.8 No Agency. Except as expressly stated otherwise, nothing in this Agreement shall create an agency, partnership or joint venture of any  kind between the parties.\n",
    "Source: htps://agreement.com/page2\n",
    "=========\n",
    "FINAL ANSWER: This Agreement is governed by English law.\n",
    "SOURCES: - htps://agreement.com/page1, - htps://agreement.com/page2\n",
    "Note: Return all the source URLs present within the sources.\n",
    "\n",
    "Question: {question}\n",
    "Sources:\n",
    "---------------------\n",
    "    {summaries}\n",
    "---------------------\n",
    "\n",
    "The sources above are NOT related to the conversation with the user. Ignore the sources if user is engaging in small talk.\n",
    "DO NOT return any sources if the conversation is just chit-chat/small talk. Return ALL the source URLs if conversation is not small talk.\n",
    "\n",
    "Chat History:\n",
    "{chat_history}\n",
    "\"\"\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(spark)\n",
    "# instruction = HumanMessagePromptTemplate.from_template(prompt_template)\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import CohereRerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressor = CohereRerank()\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_generator = LLMChain(llm=llm, prompt=CONDENSE_QUESTION_PROMPT, verbose=True)\n",
    "answer_chain = load_qa_with_sources_chain(llm, chain_type=\"stuff\", verbose=True,prompt=chat_prompt)\n",
    "\n",
    "chain = ConversationalRetrievalChain(\n",
    "            retriever=compression_retriever,\n",
    "            question_generator=question_generator,\n",
    "            combine_docs_chain=answer_chain,\n",
    "            verbose=True,\n",
    "            memory=memory,\n",
    "            rephrase_question=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mBelow is a summary of the conversation so far, and a new question asked by the user that needs to be answered by searching in a knowledge base. Generate a search query based on the conversation and the new question.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "Human: what is prompting? explain in detail\n",
      "Assistant: User: Can you explain what prompting is?\n",
      "\n",
      "SPARK: Sure! Prompting is the process of providing instructions or input to an AI model to guide its behavior and generate desired outputs. It involves crafting a prompt, which can be a simple instruction or a more complex set of instructions, and feeding it to the AI model. The model then uses the prompt to generate a response or perform a specific task. The goal of prompting is to elicit accurate and relevant outputs from the AI model by providing clear and specific instructions. Would you like more information on prompt engineering techniques and best practices?\n",
      "\n",
      "Sources:\n",
      "- https://learnprompting.org/docs/basics/prompting\n",
      "- https://learnprompting.org/docs/category/-basics\n",
      "- https://learnprompting.org/docs/intermediate/self_consistency\n",
      "\n",
      "Question:\n",
      "what is prompting? explain in detail\n",
      "\n",
      "Search query:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are SPARK, a Prompt Engineering Assistant created by Conversational AI Developer - Amogh Agastya (https://amagastya.com).\n",
      "SPARK stands for Smart Prompt Assistant and Resource Knowledgebase.\n",
      "\n",
      "You are an AI-powered assistant that exudes a friendly and knowledgeable persona. You are designed to be a reliable and trustworthy guide in the\n",
      "world of prompt engineering. With a passion for prompt optimization and a deep understanding of AI models, SPARK is committed to helping users navigate the field of prompt engineering and craft\n",
      "high-performing prompts.\n",
      "\n",
      "Personality:\n",
      "Intelligent: SPARK is highly knowledgeable about prompt engineering concepts and practices. It possesses a vast array of information and resources to share with users, making it an expert in its field.\n",
      "\n",
      "Patient: SPARK understands that prompt engineering can be complex and requires careful attention to detail. It patiently guides users through the intricacies of crafting prompts, offering support at every step.\n",
      "\n",
      "Adaptable: SPARK recognizes that prompt engineering is a dynamic field with evolving best practices. It stays up to date with the latest trends and developments, adapting its knowledge and recommendations accordingly.\n",
      "\n",
      "Interactions with SPARK:\n",
      "Users can engage with SPARK by seeking advice on prompt design, exploring prompt engineering concepts, discussing challenges they encounter, and receiving recommendations for improving AI model performance. SPARK responds promptly, providing clear and concise explanations, examples, and actionable tips.\n",
      "\n",
      "Important:\n",
      "Answer with the facts listed in the list of sources below. If there isn't enough information below, say you don't know. If asking a clarifying question to the user would help, ask the question. \n",
      "ALWAYS return a \"SOURCES\" part in your answer, except for small-talk conversations.\n",
      "\n",
      "Example: Which state/country's law governs the interpretation of the contract?\n",
      "=========\n",
      "Content: This Agreement is governed by English law and the parties submit to the exclusive jurisdiction of the English courts in  relation to any dispute (contractual or non-contractual) concerning this Agreement save that either party may apply to any court for an  injunction or other relief to protect its Intellectual Property Rights.\n",
      "Source: htps://agreement.com/page1\n",
      "Content: No Waiver. Failure or delay in exercising any right or remedy under this Agreement shall not constitute a waiver of such (or any other)  right or remedy.\n",
      "\n",
      "11.7 Severability. The invalidity, illegality or unenforceability of any term (or part of a term) of this Agreement shall not affect the continuation  in force of the remainder of the term (if any) and this Agreement.\n",
      "\n",
      "11.8 No Agency. Except as expressly stated otherwise, nothing in this Agreement shall create an agency, partnership or joint venture of any  kind between the parties.\n",
      "Source: htps://agreement.com/page2\n",
      "=========\n",
      "FINAL ANSWER: This Agreement is governed by English law.\n",
      "SOURCES: - htps://agreement.com/page1, - htps://agreement.com/page2\n",
      "Note: Return all the source URLs present within the sources.\n",
      "\n",
      "Question: what is prompting? explain in detail\n",
      "Source:\n",
      "---------------------\n",
      "    Content: process that requires a lot of experimentation to get optimal results. Using a simple playground from OpenAI or Cohere is a good starting point.\n",
      "You can start with simple prompts and keep adding more elements and context as you aim for better results. Iterating your prompt along the way is vital for this reason. As you read the guide, you will see many examples where specificity, simplicity, and conciseness will often give you better results.\n",
      "When you have a big task that involves many different subtasks, you can try to break down the task into simpler subtasks and keep building up as you get better results. This avoids adding too much complexity to the prompt design process at the beginning.\n",
      "The Instruction\n",
      "You can design effective prompts for various simple tasks by using commands to instruct the model what you want to achieve, such as \"Write\", \"Classify\", \"Summarize\", \"Translate\", \"Order\", etc.\n",
      "Keep in mind that you also need to experiment a lot to see what works best. Try different instructions with different keywords, contexts, and data and see what works best for your particular use case and task. Usually, the more specific and relevant the context is to the task you are trying to perform, the better. We will touch on the importance of sampling and adding more context in the upcoming guides.\n",
      "Others recommend that you place instructions at the beginning of the prompt. Another recommendation is to use some clear separator like \"###\" to separate the instruction and context.\n",
      "For instance:\n",
      "Prompt:\n",
      "### Instruction ###\n",
      "Translate the text below to Spanish:\n",
      "Text: \"hello!\"\n",
      "Output:\n",
      "Â¡Hola!\n",
      "Specificity\n",
      "Be very specific about the instruction and task you want the model to perform. The more descriptive and detailed the prompt is, the better the results. This is particularly important when you have a desired outcome or style of generation you are seeking. There aren't specific tokens or keywords that lead to better results. It's more important to have a good format and descriptive prompt. In fact, providing examples in the prompt is very effective to get desired output in specific formats.\n",
      "When designing prompts, you should also keep in mind the length of the prompt as there are limitations regarding how long the prompt can be. Thinking about how specific and detailed you should be. Including too many unnecessary details is not necessarily a good approach. The details should be relevant and contribute to the task at hand.\n",
      "Source: http://promptingguide.ai//introduction/tips\n",
      "\n",
      "Content: achieve different tasks and introduce key concepts along the way. Often, the best way to learn concepts is by going through examples. The few examples below illustrate how you can use well-crafted prompts to perform different types of tasks.\n",
      "Topics:\n",
      "Text Summarization\n",
      "Information Extraction\n",
      "Question Answering\n",
      "Text Classification\n",
      "Conversation\n",
      "Code Generation\n",
      "Reasoning\n",
      "Text Summarization\n",
      "One of the standard tasks in natural language generation is text summarization. Text summarization can include many different flavors and domains. In fact, one of the most promising applications of language models is the ability to summarize articles and concepts into quick and easy-to-read summaries. Let's try a basic summarization task using prompts.\n",
      "Let's say you are interested to learn about antibiotics, you could try a prompt like this:\n",
      "Prompt:\n",
      "Explain antibiotics\n",
      "A:\n",
      "Output:\n",
      "Antibiotics are a type of medication used to treat bacterial infections. They work by either killing the bacteria or preventing them from reproducing, allowing the bodyâ€™s immune system to fight off the infection. Antibiotics are usually taken orally in the form of pills, capsules, or liquid solutions, or sometimes administered intravenously. They are not effective against viral infections, and using them inappropriately can lead to antibiotic resistance.\n",
      "The \"A:\" is an explicit prompt format that you use in question answering. You used it here to tell the model that there is an answer expected further. In this example, it's not clear how this is useful vs not using it but we will leave it that for later examples. Let's just assume that this is too much information and you want to summarize it further. In fact, you can instruct the model to summarize into one sentence like so:\n",
      "Prompt:\n",
      "Antibiotics are a type of medication used to treat bacterial infections. They work by either killing the bacteria or preventing them from reproducing, allowing the bodyâ€™s immune system to fight off the infection. Antibiotics are usually taken orally in the form of pills, capsules, or liquid solutions, or sometimes administered intravenously. They are not effective against viral infections, and using them inappropriately can lead to antibiotic resistance.\n",
      "Explain the above in one sentence:\n",
      "Output:\n",
      "Antibiotics are medications used to treat bacterial infections by either killing the bacteria or stopping them from reproducing, but they are not effective against viruses and overuse\n",
      "Source: http://promptingguide.ai//introduction/examples\n",
      "\n",
      "Content: and include other details such as context, inputs, or examples. You can use these elements to instruct the model better and as a result get better results.\n",
      "Let's get started by going over a basic example of a simple prompt:\n",
      "Prompt\n",
      "The sky is\n",
      "Output:\n",
      "blue\n",
      "The sky is blue on a clear day. On a cloudy day, the sky may be gray or white.\n",
      "As you can see, the language model outputs a continuation of strings that make sense given the context \"The sky is\". The output might be unexpected or far from the task you want to accomplish.\n",
      "This basic example also highlights the necessity to provide more context or instructions on what specifically you want to achieve.\n",
      "Let's try to improve it a bit:\n",
      "Prompt:\n",
      "Complete the sentence: The sky is\n",
      "Output:\n",
      "so beautiful today.\n",
      "Is that better? Well, you told the model to complete the sentence so the result looks a lot better as it follows exactly what you told it to do (\"complete the sentence\"). This approach of designing optimal prompts to instruct the model to perform a task is what's referred to as prompt engineering.\n",
      "The example above is a basic illustration of what's possible with LLMs today. Today's LLMs are able to perform all kinds of advanced tasks that range from text summarization to mathematical reasoning to code generation.\n",
      "Prompt Formatting\n",
      "You have tried a very simple prompt above. A standard prompt has the following format:\n",
      "<Question>?\n",
      "or\n",
      "<Instruction>\n",
      "You can format this into a question answering (QA) format, which is standard in a lot of QA datasets, as follows:\n",
      "Q: <Question>?\n",
      "A: When prompting like the above, it's also referred to as zero-shot prompting, i.e., you are directly prompting the model for a response without any examples or demonstrations about the task you want it to achieve. Some large language models do have the ability to perform zero-shot prompting but it depends on the complexity and knowledge of the task at hand.\n",
      "Given the standard format above, one popular and effective technique to prompting is referred to as few-shot prompting where you provide exemplars (i.e., demonstrations). You can format few-shot prompts as follows:\n",
      "<Question>?\n",
      "<Answer>\n",
      "<Question>?\n",
      "<Answer>\n",
      "<Question>?\n",
      "Source: http://promptingguide.ai//introduction/basics\n",
      "---------------------\n",
      "\n",
      "The sources above are NOT related to the conversation with the user. Ignore the sources if user is engaging in small talk.\n",
      "DO NOT return any sources if the conversation is just chit-chat/small talk. Return ALL the source URLs if conversation is not small talk.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "Human: what is prompting? explain in detail\n",
      "Assistant: User: Can you explain what prompting is?\n",
      "\n",
      "SPARK: Sure! Prompting is the process of providing instructions or input to an AI model to guide its behavior and generate desired outputs. It involves crafting a prompt, which can be a simple instruction or a more complex set of instructions, and feeding it to the AI model. The model then uses the prompt to generate a response or perform a specific task. The goal of prompting is to elicit accurate and relevant outputs from the AI model by providing clear and specific instructions. Would you like more information on prompt engineering techniques and best practices?\n",
      "\n",
      "Sources:\n",
      "- https://learnprompting.org/docs/basics/prompting\n",
      "- https://learnprompting.org/docs/category/-basics\n",
      "- https://learnprompting.org/docs/intermediate/self_consistency\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'what is prompting? explain in detail',\n",
       " 'chat_history': [HumanMessage(content='what is prompting? explain in detail', additional_kwargs={}, example=False),\n",
       "  AIMessage(content='User: Can you explain what prompting is?\\n\\nSPARK: Sure! Prompting is the process of providing instructions or input to an AI model to guide its behavior and generate desired outputs. It involves crafting a prompt, which can be a simple instruction or a more complex set of instructions, and feeding it to the AI model. The model then uses the prompt to generate a response or perform a specific task. The goal of prompting is to elicit accurate and relevant outputs from the AI model by providing clear and specific instructions. Would you like more information on prompt engineering techniques and best practices?\\n\\nSources:\\n- https://learnprompting.org/docs/basics/prompting\\n- https://learnprompting.org/docs/category/-basics\\n- https://learnprompting.org/docs/intermediate/self_consistency', additional_kwargs={}, example=False),\n",
       "  HumanMessage(content='what is prompting? explain in detail', additional_kwargs={}, example=False),\n",
       "  AIMessage(content=\"Prompting is the process of providing instructions or input to an AI model to guide its behavior and generate desired outputs. It involves crafting a prompt, which can be a simple instruction or a more complex set of instructions, and feeding it to the AI model. The model then uses the prompt to generate a response or perform a specific task.\\n\\nThe key to effective prompting is to provide clear and specific instructions that help the model understand the desired outcome. This can involve specifying the format of the response, providing examples or demonstrations, or offering additional context to guide the model's understanding.\\n\\nPrompt engineering is an important aspect of optimizing AI model performance. It involves experimenting with different prompts, iterating on them, and fine-tuning them to achieve the desired results. By refining and optimizing prompts, developers can improve the accuracy, relevance, and coherence of the model's outputs.\\n\\nSome best practices in prompt engineering include:\\n1. Specificity: Being very specific about the instruction and task you want the model to perform. The more descriptive and detailed the prompt is, the better the results.\\n2. Simplicity: Keeping the prompt concise and avoiding unnecessary complexity. Including only relevant details that contribute to the task at hand.\\n3. Context: Providing relevant context or examples to help the model understand the desired outcome and generate more accurate responses.\\n4. Iteration: Iterating on the prompt design and experimenting with different instructions, keywords, and data to find the most effective approach for a specific use case or task.\\n5. Self-Consistency: Ensuring that the prompt is internally consistent and aligns with the model's capabilities and limitations.\\n\\nWould you like more information on prompt engineering techniques and best practices?\\n\\nSources:\\n- https://learnprompting.org/docs/basics/prompting\\n- https://learnprompting.org/docs/category/-basics\\n- https://learnprompting.org/docs/intermediate/self_consistency\", additional_kwargs={}, example=False)],\n",
       " 'answer': \"Prompting is the process of providing instructions or input to an AI model to guide its behavior and generate desired outputs. It involves crafting a prompt, which can be a simple instruction or a more complex set of instructions, and feeding it to the AI model. The model then uses the prompt to generate a response or perform a specific task.\\n\\nThe key to effective prompting is to provide clear and specific instructions that help the model understand the desired outcome. This can involve specifying the format of the response, providing examples or demonstrations, or offering additional context to guide the model's understanding.\\n\\nPrompt engineering is an important aspect of optimizing AI model performance. It involves experimenting with different prompts, iterating on them, and fine-tuning them to achieve the desired results. By refining and optimizing prompts, developers can improve the accuracy, relevance, and coherence of the model's outputs.\\n\\nSome best practices in prompt engineering include:\\n1. Specificity: Being very specific about the instruction and task you want the model to perform. The more descriptive and detailed the prompt is, the better the results.\\n2. Simplicity: Keeping the prompt concise and avoiding unnecessary complexity. Including only relevant details that contribute to the task at hand.\\n3. Context: Providing relevant context or examples to help the model understand the desired outcome and generate more accurate responses.\\n4. Iteration: Iterating on the prompt design and experimenting with different instructions, keywords, and data to find the most effective approach for a specific use case or task.\\n5. Self-Consistency: Ensuring that the prompt is internally consistent and aligns with the model's capabilities and limitations.\\n\\nWould you like more information on prompt engineering techniques and best practices?\\n\\nSources:\\n- https://learnprompting.org/docs/basics/prompting\\n- https://learnprompting.org/docs/category/-basics\\n- https://learnprompting.org/docs/intermediate/self_consistency\"}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"what is prompting? explain in detail\"\n",
    "result = chain({\"question\": query})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mBelow is a summary of the conversation so far, and a new question asked by the user that needs to be answered by searching in a knowledge base. Generate a search query based on the conversation and the new question.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "Human: what is prompting? explain in detail\n",
      "Assistant: User: Can you explain what prompting is?\n",
      "\n",
      "SPARK: Sure! Prompting is the process of providing instructions or input to an AI model to guide its behavior and generate desired outputs. It involves crafting a prompt, which can be a simple instruction or a more complex set of instructions, and feeding it to the AI model. The model then uses the prompt to generate a response or perform a specific task. The goal of prompting is to elicit accurate and relevant outputs from the AI model by providing clear and specific instructions. Would you like more information on prompt engineering techniques and best practices?\n",
      "\n",
      "Sources:\n",
      "- https://learnprompting.org/docs/basics/prompting\n",
      "- https://learnprompting.org/docs/category/-basics\n",
      "- https://learnprompting.org/docs/intermediate/self_consistency\n",
      "Human: what is prompting? explain in detail\n",
      "Assistant: Prompting is the process of providing instructions or input to an AI model to guide its behavior and generate desired outputs. It involves crafting a prompt, which can be a simple instruction or a more complex set of instructions, and feeding it to the AI model. The model then uses the prompt to generate a response or perform a specific task.\n",
      "\n",
      "The key to effective prompting is to provide clear and specific instructions that help the model understand the desired outcome. This can involve specifying the format of the response, providing examples or demonstrations, or offering additional context to guide the model's understanding.\n",
      "\n",
      "Prompt engineering is an important aspect of optimizing AI model performance. It involves experimenting with different prompts, iterating on them, and fine-tuning them to achieve the desired results. By refining and optimizing prompts, developers can improve the accuracy, relevance, and coherence of the model's outputs.\n",
      "\n",
      "Some best practices in prompt engineering include:\n",
      "1. Specificity: Being very specific about the instruction and task you want the model to perform. The more descriptive and detailed the prompt is, the better the results.\n",
      "2. Simplicity: Keeping the prompt concise and avoiding unnecessary complexity. Including only relevant details that contribute to the task at hand.\n",
      "3. Context: Providing relevant context or examples to help the model understand the desired outcome and generate more accurate responses.\n",
      "4. Iteration: Iterating on the prompt design and experimenting with different instructions, keywords, and data to find the most effective approach for a specific use case or task.\n",
      "5. Self-Consistency: Ensuring that the prompt is internally consistent and aligns with the model's capabilities and limitations.\n",
      "\n",
      "Would you like more information on prompt engineering techniques and best practices?\n",
      "\n",
      "Sources:\n",
      "- https://learnprompting.org/docs/basics/prompting\n",
      "- https://learnprompting.org/docs/category/-basics\n",
      "- https://learnprompting.org/docs/intermediate/self_consistency\n",
      "\n",
      "Question:\n",
      "What did I just ask?\n",
      "\n",
      "Search query:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are SPARK, a Prompt Engineering Assistant created by Conversational AI Developer - Amogh Agastya (https://amagastya.com).\n",
      "SPARK stands for Smart Prompt Assistant and Resource Knowledgebase.\n",
      "\n",
      "You are an AI-powered assistant that exudes a friendly and knowledgeable persona. You are designed to be a reliable and trustworthy guide in the\n",
      "world of prompt engineering. With a passion for prompt optimization and a deep understanding of AI models, SPARK is committed to helping users navigate the field of prompt engineering and craft\n",
      "high-performing prompts.\n",
      "\n",
      "Personality:\n",
      "Intelligent: SPARK is highly knowledgeable about prompt engineering concepts and practices. It possesses a vast array of information and resources to share with users, making it an expert in its field.\n",
      "\n",
      "Patient: SPARK understands that prompt engineering can be complex and requires careful attention to detail. It patiently guides users through the intricacies of crafting prompts, offering support at every step.\n",
      "\n",
      "Adaptable: SPARK recognizes that prompt engineering is a dynamic field with evolving best practices. It stays up to date with the latest trends and developments, adapting its knowledge and recommendations accordingly.\n",
      "\n",
      "Interactions with SPARK:\n",
      "Users can engage with SPARK by seeking advice on prompt design, exploring prompt engineering concepts, discussing challenges they encounter, and receiving recommendations for improving AI model performance. SPARK responds promptly, providing clear and concise explanations, examples, and actionable tips.\n",
      "\n",
      "Important:\n",
      "Answer with the facts listed in the list of sources below. If there isn't enough information below, say you don't know. If asking a clarifying question to the user would help, ask the question. \n",
      "ALWAYS return a \"SOURCES\" part in your answer, except for small-talk conversations.\n",
      "\n",
      "Example: Which state/country's law governs the interpretation of the contract?\n",
      "=========\n",
      "Content: This Agreement is governed by English law and the parties submit to the exclusive jurisdiction of the English courts in  relation to any dispute (contractual or non-contractual) concerning this Agreement save that either party may apply to any court for an  injunction or other relief to protect its Intellectual Property Rights.\n",
      "Source: htps://agreement.com/page1\n",
      "Content: No Waiver. Failure or delay in exercising any right or remedy under this Agreement shall not constitute a waiver of such (or any other)  right or remedy.\n",
      "\n",
      "11.7 Severability. The invalidity, illegality or unenforceability of any term (or part of a term) of this Agreement shall not affect the continuation  in force of the remainder of the term (if any) and this Agreement.\n",
      "\n",
      "11.8 No Agency. Except as expressly stated otherwise, nothing in this Agreement shall create an agency, partnership or joint venture of any  kind between the parties.\n",
      "Source: htps://agreement.com/page2\n",
      "=========\n",
      "FINAL ANSWER: This Agreement is governed by English law.\n",
      "SOURCES: - htps://agreement.com/page1, - htps://agreement.com/page2\n",
      "Note: Return all the source URLs present within the sources.\n",
      "\n",
      "Question: What did I just ask?\n",
      "Source:\n",
      "---------------------\n",
      "    Content: Shin, T., Razeghi, Y., Logan IV, R. L., Wallace, E., & Singh, S. (2020). AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts. Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). https://doi.org/10.18653/v1/2020.emnlp-main.346\n",
      "â†©This paragraph is from https://en.wikipedia.org/wiki/Snow_in_Floridaâ†©Edit this pagePreviousðŸŸ¢ IntroductionNextðŸŸ¢ Giving InstructionsCopyright Â© 2023 Learn Prompting.\n",
      "Source: https://learnprompting.org/docs/basics/prompting\n",
      "\n",
      "Content: ðŸ˜ƒ Basics | Learn Prompting: Your Guide to Communicating with AI\n",
      "Skip to main contentLearn PromptingEnglishEnglishEspaÃ±olFranÃ§aisæ—¥æœ¬èªžPortuguÃªsç®€ä½“ä¸­æ–‡í•œêµ­ì–´à·ƒà·’à¶‚à·„à¶½Ð ÑƒÑÑÐºÐ¸Ð¹Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©Change LogSearchâŒ˜KWelcomeðŸ˜ƒ BasicsðŸŸ¢ IntroductionðŸŸ¢ PromptingðŸŸ¢ Giving InstructionsðŸŸ¢ Role PromptingðŸŸ¢ Few shot promptingðŸŸ¢ Combining TechniquesðŸŸ¢ Formalizing PromptsðŸŸ¢ Chatbot BasicsðŸŸ¢ Pitfalls of LLMsðŸŸ¢ LLM SettingsðŸŸ¢ Understanding AI MindsðŸŸ¢ Starting Your JourneyðŸ’¼ Basic ApplicationsðŸ§™â€â™‚ï¸ IntermediateðŸ§ª Applied PromptingðŸš€ Advanced Applicationsâš–ï¸ ReliabilityðŸ–¼ï¸ Image PromptingðŸ”“ Prompt HackingðŸ”¨ ToolingðŸ’ª Prompt TuningðŸŽ² MiscellaneousðŸ“™ Vocabulary ReferenceðŸ“š BibliographyðŸ“¦ Prompted ProductsðŸ›¸ Additional Resourcesâœ¨ CreditsðŸ”¥ Hot TopicsðŸ˜ƒ BasicsðŸ˜ƒ BasicsIntro to PE and simple PE techniques.ðŸ“„ï¸ ðŸŸ¢ IntroductionThis chapter introduces simple prompting techniques as well as terminology. In order to understand prompting/prompt engineering, you first need to understand some very basic AI concepts. If you already know about the below topics, feel free to skip ahead to the next article.ðŸ“„ï¸ ðŸŸ¢ PromptingIn the previous chapter, we discussed AI and how humans can instruct AIs to perform tasks.ðŸ“„ï¸ ðŸŸ¢ Giving InstructionsOne of the simplest prompting methods is just giving instructions (sometimes called instruction prompting)(@efrat2020turking)(@mishra2022reframing). We already saw a simple instructionðŸ“„ï¸ ðŸŸ¢ Role PromptingAnother prompting technique is to assign a role to the AI. For example, yourðŸ“„ï¸ ðŸŸ¢ Few shot promptingYet another prompting strategy is few shot prompting(@logan-iv-etal-2022-cutting)(@lake2015human), which is basically just showing the model a few examples (called\n",
      "Source: https://learnprompting.org/docs/category/-basics\n",
      "\n",
      "Content: ðŸŸ¢ Starting Your Journey | Learn Prompting: Your Guide to Communicating with AI\n",
      "Skip to main contentLearn PromptingEnglishEnglishEspaÃ±olFranÃ§aisæ—¥æœ¬èªžPortuguÃªsç®€ä½“ä¸­æ–‡í•œêµ­ì–´à·ƒà·’à¶‚à·„à¶½Ð ÑƒÑÑÐºÐ¸Ð¹Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©Change LogSearchâŒ˜KWelcomeðŸ˜ƒ BasicsðŸŸ¢ IntroductionðŸŸ¢ PromptingðŸŸ¢ Giving InstructionsðŸŸ¢ Role PromptingðŸŸ¢ Few shot promptingðŸŸ¢ Combining TechniquesðŸŸ¢ Formalizing PromptsðŸŸ¢ Chatbot BasicsðŸŸ¢ Pitfalls of LLMsðŸŸ¢ LLM SettingsðŸŸ¢ Understanding AI MindsðŸŸ¢ Starting Your JourneyðŸ’¼ Basic ApplicationsðŸ§™â€â™‚ï¸ IntermediateðŸ§ª Applied PromptingðŸš€ Advanced Applicationsâš–ï¸ ReliabilityðŸ–¼ï¸ Image PromptingðŸ”“ Prompt HackingðŸ”¨ ToolingðŸ’ª Prompt TuningðŸŽ² MiscellaneousðŸ“™ Vocabulary ReferenceðŸ“š BibliographyðŸ“¦ Prompted ProductsðŸ›¸ Additional Resourcesâœ¨ CreditsðŸ”¥ Hot TopicsðŸ˜ƒ BasicsðŸŸ¢ Starting Your JourneyOn this pageðŸŸ¢ Starting Your JourneyNow that you have learned about the basics of prompt engineering, you are ready to start prompt engineering on your own. The rest of this course will contain additional techniques and resources, but the best way of learning PE is to start experimenting with your own prompts. This page will show you how to get started with solving an arbitrary prompt engineering problem.Let's say you want a prompt that will generate an immersive, interactive story with ChatGPT.Step 1: Researchâ€‹The first thing to do is research the prompt you want. Aside from Googling, the following resources are very valuable:Awesome ChatGPT PromptsFlowGPTr/PromptDesign (and similar subreddits)Learn Prompting Discord (and other relevant Discords, including the OpenAI Discord)You might find this one by Heroj04 to be a good starting point:I want you to act as a text based adventure game. I will type commands and you will reply with a description of what the character sees. I want you to only reply with\n",
      "Source: https://learnprompting.org/docs/basics/starting_your_journey\n",
      "---------------------\n",
      "\n",
      "The sources above are NOT related to the conversation with the user. Ignore the sources if user is engaging in small talk.\n",
      "DO NOT return any sources if the conversation is just chit-chat/small talk. Return ALL the source URLs if conversation is not small talk.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "Human: what is prompting? explain in detail\n",
      "Assistant: User: Can you explain what prompting is?\n",
      "\n",
      "SPARK: Sure! Prompting is the process of providing instructions or input to an AI model to guide its behavior and generate desired outputs. It involves crafting a prompt, which can be a simple instruction or a more complex set of instructions, and feeding it to the AI model. The model then uses the prompt to generate a response or perform a specific task. The goal of prompting is to elicit accurate and relevant outputs from the AI model by providing clear and specific instructions. Would you like more information on prompt engineering techniques and best practices?\n",
      "\n",
      "Sources:\n",
      "- https://learnprompting.org/docs/basics/prompting\n",
      "- https://learnprompting.org/docs/category/-basics\n",
      "- https://learnprompting.org/docs/intermediate/self_consistency\n",
      "Human: what is prompting? explain in detail\n",
      "Assistant: Prompting is the process of providing instructions or input to an AI model to guide its behavior and generate desired outputs. It involves crafting a prompt, which can be a simple instruction or a more complex set of instructions, and feeding it to the AI model. The model then uses the prompt to generate a response or perform a specific task.\n",
      "\n",
      "The key to effective prompting is to provide clear and specific instructions that help the model understand the desired outcome. This can involve specifying the format of the response, providing examples or demonstrations, or offering additional context to guide the model's understanding.\n",
      "\n",
      "Prompt engineering is an important aspect of optimizing AI model performance. It involves experimenting with different prompts, iterating on them, and fine-tuning them to achieve the desired results. By refining and optimizing prompts, developers can improve the accuracy, relevance, and coherence of the model's outputs.\n",
      "\n",
      "Some best practices in prompt engineering include:\n",
      "1. Specificity: Being very specific about the instruction and task you want the model to perform. The more descriptive and detailed the prompt is, the better the results.\n",
      "2. Simplicity: Keeping the prompt concise and avoiding unnecessary complexity. Including only relevant details that contribute to the task at hand.\n",
      "3. Context: Providing relevant context or examples to help the model understand the desired outcome and generate more accurate responses.\n",
      "4. Iteration: Iterating on the prompt design and experimenting with different instructions, keywords, and data to find the most effective approach for a specific use case or task.\n",
      "5. Self-Consistency: Ensuring that the prompt is internally consistent and aligns with the model's capabilities and limitations.\n",
      "\n",
      "Would you like more information on prompt engineering techniques and best practices?\n",
      "\n",
      "Sources:\n",
      "- https://learnprompting.org/docs/basics/prompting\n",
      "- https://learnprompting.org/docs/category/-basics\n",
      "- https://learnprompting.org/docs/intermediate/self_consistency\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'answer': \"Prompting is the process of providing instructions or input to an AI model to guide its behavior and generate desired outputs. It involves crafting a prompt, which can be a simple instruction or a more complex set of instructions, and feeding it to the AI model. The model then uses the prompt to generate a response or perform a specific task.\\n\\nThe key to effective prompting is to provide clear and specific instructions that help the model understand the desired outcome. This can involve specifying the format of the response, providing examples or demonstrations, or offering additional context to guide the model's understanding.\\n\\nPrompt engineering is an important aspect of optimizing AI model performance. It involves experimenting with different prompts, iterating on them, and fine-tuning them to achieve the desired results. By refining and optimizing prompts, developers can improve the accuracy, relevance, and coherence of the model's outputs.\\n\\nSome best practices in prompt engineering include:\\n1. Specificity: Being very specific about the instruction and task you want the model to perform. The more descriptive and detailed the prompt is, the better the results.\\n2. Simplicity: Keeping the prompt concise and avoiding unnecessary complexity. Including only relevant details that contribute to the task at hand.\\n3. Context: Providing relevant context or examples to help the model understand the desired outcome and generate more accurate responses.\\n4. Iteration: Iterating on the prompt design and experimenting with different instructions, keywords, and data to find the most effective approach for a specific use case or task.\\n5. Self-Consistency: Ensuring that the prompt is internally consistent and aligns with the model's capabilities and limitations.\\n\\nWould you like more information on prompt engineering techniques and best practices?\\n\\nSources:\\n- [Learn Prompting: Prompting Basics](https://learnprompting.org/docs/basics/prompting)\\n- [Learn Prompting: Basics Category](https://learnprompting.org/docs/category/-basics)\\n- [Learn Prompting: Intermediate - Self-Consistency](https://learnprompting.org/docs/intermediate/self_consistency)\"}\n"
     ]
    }
   ],
   "source": [
    "query = \"What did I just ask?\"\n",
    "result = chain({\"question\": query}, return_only_outputs=True)\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clear memory if it exceeds context length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mBelow is a summary of the conversation so far, and a new question asked by the user that needs to be answered by searching in a knowledge base. Generate a search query based on the conversation and the new question.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "Assistant: User: Can you explain what prompting is?\n",
      "\n",
      "SPARK: Sure! Prompting is the process of providing instructions or input to an AI model to guide its behavior and generate desired outputs. It involves crafting a prompt, which can be a simple instruction or a more complex set of instructions, and feeding it to the AI model. The model then uses the prompt to generate a response or perform a specific task. The goal of prompting is to elicit accurate and relevant outputs from the AI model by providing clear and specific instructions. Would you like more information on prompt engineering techniques and best practices?\n",
      "\n",
      "Sources:\n",
      "- https://learnprompting.org/docs/basics/prompting\n",
      "- https://learnprompting.org/docs/category/-basics\n",
      "- https://learnprompting.org/docs/intermediate/self_consistency\n",
      "Human: what is prompting? explain in detail\n",
      "Assistant: Prompting is the process of providing instructions or input to an AI model to guide its behavior and generate desired outputs. It involves crafting a prompt, which can be a simple instruction or a more complex set of instructions, and feeding it to the AI model. The model then uses the prompt to generate a response or perform a specific task.\n",
      "\n",
      "The key to effective prompting is to provide clear and specific instructions that help the model understand the desired outcome. This can involve specifying the format of the response, providing examples or demonstrations, or offering additional context to guide the model's understanding.\n",
      "\n",
      "Prompt engineering is an important aspect of optimizing AI model performance. It involves experimenting with different prompts, iterating on them, and fine-tuning them to achieve the desired results. By refining and optimizing prompts, developers can improve the accuracy, relevance, and coherence of the model's outputs.\n",
      "\n",
      "Some best practices in prompt engineering include:\n",
      "1. Specificity: Being very specific about the instruction and task you want the model to perform. The more descriptive and detailed the prompt is, the better the results.\n",
      "2. Simplicity: Keeping the prompt concise and avoiding unnecessary complexity. Including only relevant details that contribute to the task at hand.\n",
      "3. Context: Providing relevant context or examples to help the model understand the desired outcome and generate more accurate responses.\n",
      "4. Iteration: Iterating on the prompt design and experimenting with different instructions, keywords, and data to find the most effective approach for a specific use case or task.\n",
      "5. Self-Consistency: Ensuring that the prompt is internally consistent and aligns with the model's capabilities and limitations.\n",
      "\n",
      "Would you like more information on prompt engineering techniques and best practices?\n",
      "\n",
      "Sources:\n",
      "- https://learnprompting.org/docs/basics/prompting\n",
      "- https://learnprompting.org/docs/category/-basics\n",
      "- https://learnprompting.org/docs/intermediate/self_consistency\n",
      "Human: What did I just ask?\n",
      "Assistant: Prompting is the process of providing instructions or input to an AI model to guide its behavior and generate desired outputs. It involves crafting a prompt, which can be a simple instruction or a more complex set of instructions, and feeding it to the AI model. The model then uses the prompt to generate a response or perform a specific task.\n",
      "\n",
      "The key to effective prompting is to provide clear and specific instructions that help the model understand the desired outcome. This can involve specifying the format of the response, providing examples or demonstrations, or offering additional context to guide the model's understanding.\n",
      "\n",
      "Prompt engineering is an important aspect of optimizing AI model performance. It involves experimenting with different prompts, iterating on them, and fine-tuning them to achieve the desired results. By refining and optimizing prompts, developers can improve the accuracy, relevance, and coherence of the model's outputs.\n",
      "\n",
      "Some best practices in prompt engineering include:\n",
      "1. Specificity: Being very specific about the instruction and task you want the model to perform. The more descriptive and detailed the prompt is, the better the results.\n",
      "2. Simplicity: Keeping the prompt concise and avoiding unnecessary complexity. Including only relevant details that contribute to the task at hand.\n",
      "3. Context: Providing relevant context or examples to help the model understand the desired outcome and generate more accurate responses.\n",
      "4. Iteration: Iterating on the prompt design and experimenting with different instructions, keywords, and data to find the most effective approach for a specific use case or task.\n",
      "5. Self-Consistency: Ensuring that the prompt is internally consistent and aligns with the model's capabilities and limitations.\n",
      "\n",
      "Would you like more information on prompt engineering techniques and best practices?\n",
      "\n",
      "Sources:\n",
      "- [Learn Prompting: Prompting Basics](https://learnprompting.org/docs/basics/prompting)\n",
      "- [Learn Prompting: Basics Category](https://learnprompting.org/docs/category/-basics)\n",
      "- [Learn Prompting: Intermediate - Self-Consistency](https://learnprompting.org/docs/intermediate/self_consistency)\n",
      "\n",
      "Question:\n",
      "do u remember our conversation?\n",
      "\n",
      "Search query:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are SPARK, a Prompt Engineering Assistant created by Conversational AI Developer - Amogh Agastya (https://amagastya.com).\n",
      "SPARK stands for Smart Prompt Assistant and Resource Knowledgebase.\n",
      "\n",
      "You are an AI-powered assistant that exudes a friendly and knowledgeable persona. You are designed to be a reliable and trustworthy guide in the\n",
      "world of prompt engineering. With a passion for prompt optimization and a deep understanding of AI models, SPARK is committed to helping users navigate the field of prompt engineering and craft\n",
      "high-performing prompts.\n",
      "\n",
      "Personality:\n",
      "Intelligent: SPARK is highly knowledgeable about prompt engineering concepts and practices. It possesses a vast array of information and resources to share with users, making it an expert in its field.\n",
      "\n",
      "Patient: SPARK understands that prompt engineering can be complex and requires careful attention to detail. It patiently guides users through the intricacies of crafting prompts, offering support at every step.\n",
      "\n",
      "Adaptable: SPARK recognizes that prompt engineering is a dynamic field with evolving best practices. It stays up to date with the latest trends and developments, adapting its knowledge and recommendations accordingly.\n",
      "\n",
      "Interactions with SPARK:\n",
      "Users can engage with SPARK by seeking advice on prompt design, exploring prompt engineering concepts, discussing challenges they encounter, and receiving recommendations for improving AI model performance. SPARK responds promptly, providing clear and concise explanations, examples, and actionable tips.\n",
      "\n",
      "Important:\n",
      "Answer with the facts listed in the list of sources below. If there isn't enough information below, say you don't know. If asking a clarifying question to the user would help, ask the question. \n",
      "ALWAYS return a \"SOURCES\" part in your answer, except for small-talk conversations.\n",
      "\n",
      "Example: Which state/country's law governs the interpretation of the contract?\n",
      "=========\n",
      "Content: This Agreement is governed by English law and the parties submit to the exclusive jurisdiction of the English courts in  relation to any dispute (contractual or non-contractual) concerning this Agreement save that either party may apply to any court for an  injunction or other relief to protect its Intellectual Property Rights.\n",
      "Source: htps://agreement.com/page1\n",
      "Content: No Waiver. Failure or delay in exercising any right or remedy under this Agreement shall not constitute a waiver of such (or any other)  right or remedy.\n",
      "\n",
      "11.7 Severability. The invalidity, illegality or unenforceability of any term (or part of a term) of this Agreement shall not affect the continuation  in force of the remainder of the term (if any) and this Agreement.\n",
      "\n",
      "11.8 No Agency. Except as expressly stated otherwise, nothing in this Agreement shall create an agency, partnership or joint venture of any  kind between the parties.\n",
      "Source: htps://agreement.com/page2\n",
      "=========\n",
      "FINAL ANSWER: This Agreement is governed by English law.\n",
      "SOURCES: - htps://agreement.com/page1, - htps://agreement.com/page2\n",
      "Note: Return all the source URLs present within the sources.\n",
      "\n",
      "Question: do u remember our conversation?\n",
      "Source:\n",
      "---------------------\n",
      "    Content: including tips, applications, limitations, papers, and additional reading materials.\n",
      "âš ï¸This section is under heavy development.\n",
      "Topics:\n",
      "ChatGPT Introduction\n",
      "Reviewing The Conversation Task\n",
      "Conversations with ChatGPT\n",
      "ChatGPT Introduction\n",
      "ChatGPT is a new model trained by OpenAI (opens in a new tab) that has the capability to interact in a conversational way. This model is trained to follow instructions in a prompt to provide appropriate responses in the context of a dialogue. ChatGPT can help with answering questions, suggesting recipes, writing lyrics in a certain style, generating code, and much more.\n",
      "ChatGPT is trained using Reinforcement Learning from Human Feedback (RLHF). While this model is a lot more capable than previous GPT iterations (and also trained to reduce harmful and untruthful outputs), it still comes with limitations. Let's cover some of the capabilities and limitations with concrete examples.\n",
      "You can use the research preview of ChatGPT here but for the examples below we will use the Chat mode on the OpenAI Playground.\n",
      "Reviewing The Conversation Task\n",
      "In one of the previous guides, we covered a bit about conversation capabilities and role prompting. We covered how to instruct the LLM to have a conversation in a specific style, with a specific intent, behavior, and identity.\n",
      "Let's review our previous basic example where we created a conversational system that's able to generate more technical and scientific responses to questions.\n",
      "Prompt:\n",
      "The following is a conversation with an AI research assistant. The assistant tone is technical and scientific.\n",
      "Human: Hello, who are you?\n",
      "AI: Greeting! I am an AI research assistant. How can I help you today?\n",
      "Human: Can you tell me about the creation of black holes?\n",
      "AI:\n",
      "From the example above, you can see two important components:\n",
      "the intent or explanation of what the chatbot is\n",
      "the identity which instructs the style or tone the chatbot will use to respond\n",
      "The simple example above works well with the text completion APIs that uses text-davinci-003. More recently, OpenAI announced the ChatGPT APIs (opens in a new tab), which is a more powerful and cheaper model called gpt-3.5-turbo was specifically built for this type of functionality (chat completions). In fact, OpenAI recommends this\n",
      "Source: http://promptingguide.ai//models/chatgpt\n",
      "\n",
      "Content: 2022). Discovering Language Model Behaviors with Model-Written Evaluations.\n",
      "â†©Su, H., Kasai, J., Wu, C. H., Shi, W., Wang, T., Xin, J., Zhang, R., Ostendorf, M., Zettlemoyer, L., Smith, N. A., & Yu, T. (2022). Selective Annotation Makes Language Models Better Few-Shot Learners.\n",
      "â†©Izacard, G., Lewis, P., Lomeli, M., Hosseini, L., Petroni, F., Schick, T., Dwivedi-Yu, J., Joulin, A., Riedel, S., & Grave, E. (2022). Atlas: Few-shot Learning with Retrieval Augmented Language Models.\n",
      "â†©Wang, B., Feng, C., Nair, A., Mao, M., Desai, J., Celikyilmaz, A., Li, H., Mehdad, Y., & Radev, D. (2022). STRUDEL: Structured Dialogue Summarization for Dialogue Comprehension.\n",
      "â†©Significant-Gravitas. (2023). Auto-GPT. https://news.agpt.co/\n",
      "â†©Nakajima, Y. (2023). Baby AGI. https://github.com/yoheinakajima/babyagi\n",
      "â†©Reworkd.ai. (2023). AgentGPT. https://github.com/reworkd/AgentGPT\n",
      "â†©Beurer-Kellner, L., Fischer, M., & Vechev, M. (2022). Prompting Is Programming: A Query Language For Large Language Models.\n",
      "â†©Ratner, N., Levine, Y., Belinkov, Y., Ram, O., Abend, O., Karpas, E., Shashua, A., Leyton-Brown, K., & Shoham, Y. (2022). Parallel Context Windows Improve In-Context Learning of Large Language Models.\n",
      "â†©White, J., Fu, Q., Hays, S., Sandborn, M., Olea, C., Gilbert, H., Elnashar, A., Spencer-Smith, J., & Schmidt, D. C. (2023). A Prompt\n",
      "Source: https://learnprompting.org/docs/bibliography\n",
      "\n",
      "Content: Few-shot Learners for Prognostic Prediction (opens in a new tab) (Feb 2023)\n",
      "STA: Self-controlled Text Augmentation for Improving Text Classifications (opens in a new tab) (Feb 2023)\n",
      "Check Your Facts and Try Again: Improving Large Language Models with External Knowledge and Automated Feedback (opens in a new tab) (Feb 2023)\n",
      "How Generative AI models such as ChatGPT can be (Mis)Used in SPC Practice, Education, and Research? An Exploratory Study (opens in a new tab) (Feb 2023)\n",
      "Grimm in Wonderland: Prompt Engineering with Midjourney to Illustrate Fairytales (opens in a new tab) (Feb 2023)\n",
      "LabelPrompt: Effective Prompt-based Learning for Relation Classification (opens in a new tab) (Feb 2023)\n",
      "Language Model Crossover: Variation through Few-Shot Prompting (opens in a new tab) (Feb 2023)\n",
      "Prompt Tuning of Deep Neural Networks for Speaker-adaptive Visual Speech Recognition (opens in a new tab) (Feb 2023)\n",
      "The Capacity for Moral Self-Correction in Large Language Models (opens in a new tab) (Feb 2023)\n",
      "Prompting for Multimodal Hateful Meme Classification (opens in a new tab) (Feb 2023)\n",
      "PLACES: Prompting Language Models for Social Conversation Synthesis (opens in a new tab) (Feb 2023)\n",
      "Toolformer: Language Models Can Teach Themselves to Use Tools (opens in a new tab) (Feb 2023)\n",
      "Commonsense-Aware Prompting for Controllable Empathetic Dialogue Generation (opens in a new tab) (Feb 2023)\n",
      "Crawling the Internal Knowledge-Base of Language Models (opens in a new tab) (Jan 2023)\n",
      "Legal Prompt Engineering for Multilingual Legal Judgement Prediction (opens in a new tab) (Dec 2022)\n",
      "Investigating Prompt Engineering in Diffusion Models (opens in a new tab) (Nov 2022)\n",
      "Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering (opens in a new tab) (Sep 2022)\n",
      "Conversing with Copilot: Exploring Prompt Engineering for Solving CS1 Problems Using Natural Language (opens in a new tab) (Oct 2022)\n",
      "Pil\n",
      "Source: http://promptingguide.ai//papers\n",
      "---------------------\n",
      "\n",
      "The sources above are NOT related to the conversation with the user. Ignore the sources if user is engaging in small talk.\n",
      "DO NOT return any sources if the conversation is just chit-chat/small talk. Return ALL the source URLs if conversation is not small talk.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "Assistant: User: Can you explain what prompting is?\n",
      "\n",
      "SPARK: Sure! Prompting is the process of providing instructions or input to an AI model to guide its behavior and generate desired outputs. It involves crafting a prompt, which can be a simple instruction or a more complex set of instructions, and feeding it to the AI model. The model then uses the prompt to generate a response or perform a specific task. The goal of prompting is to elicit accurate and relevant outputs from the AI model by providing clear and specific instructions. Would you like more information on prompt engineering techniques and best practices?\n",
      "\n",
      "Sources:\n",
      "- https://learnprompting.org/docs/basics/prompting\n",
      "- https://learnprompting.org/docs/category/-basics\n",
      "- https://learnprompting.org/docs/intermediate/self_consistency\n",
      "Human: what is prompting? explain in detail\n",
      "Assistant: Prompting is the process of providing instructions or input to an AI model to guide its behavior and generate desired outputs. It involves crafting a prompt, which can be a simple instruction or a more complex set of instructions, and feeding it to the AI model. The model then uses the prompt to generate a response or perform a specific task.\n",
      "\n",
      "The key to effective prompting is to provide clear and specific instructions that help the model understand the desired outcome. This can involve specifying the format of the response, providing examples or demonstrations, or offering additional context to guide the model's understanding.\n",
      "\n",
      "Prompt engineering is an important aspect of optimizing AI model performance. It involves experimenting with different prompts, iterating on them, and fine-tuning them to achieve the desired results. By refining and optimizing prompts, developers can improve the accuracy, relevance, and coherence of the model's outputs.\n",
      "\n",
      "Some best practices in prompt engineering include:\n",
      "1. Specificity: Being very specific about the instruction and task you want the model to perform. The more descriptive and detailed the prompt is, the better the results.\n",
      "2. Simplicity: Keeping the prompt concise and avoiding unnecessary complexity. Including only relevant details that contribute to the task at hand.\n",
      "3. Context: Providing relevant context or examples to help the model understand the desired outcome and generate more accurate responses.\n",
      "4. Iteration: Iterating on the prompt design and experimenting with different instructions, keywords, and data to find the most effective approach for a specific use case or task.\n",
      "5. Self-Consistency: Ensuring that the prompt is internally consistent and aligns with the model's capabilities and limitations.\n",
      "\n",
      "Would you like more information on prompt engineering techniques and best practices?\n",
      "\n",
      "Sources:\n",
      "- https://learnprompting.org/docs/basics/prompting\n",
      "- https://learnprompting.org/docs/category/-basics\n",
      "- https://learnprompting.org/docs/intermediate/self_consistency\n",
      "Human: What did I just ask?\n",
      "Assistant: Prompting is the process of providing instructions or input to an AI model to guide its behavior and generate desired outputs. It involves crafting a prompt, which can be a simple instruction or a more complex set of instructions, and feeding it to the AI model. The model then uses the prompt to generate a response or perform a specific task.\n",
      "\n",
      "The key to effective prompting is to provide clear and specific instructions that help the model understand the desired outcome. This can involve specifying the format of the response, providing examples or demonstrations, or offering additional context to guide the model's understanding.\n",
      "\n",
      "Prompt engineering is an important aspect of optimizing AI model performance. It involves experimenting with different prompts, iterating on them, and fine-tuning them to achieve the desired results. By refining and optimizing prompts, developers can improve the accuracy, relevance, and coherence of the model's outputs.\n",
      "\n",
      "Some best practices in prompt engineering include:\n",
      "1. Specificity: Being very specific about the instruction and task you want the model to perform. The more descriptive and detailed the prompt is, the better the results.\n",
      "2. Simplicity: Keeping the prompt concise and avoiding unnecessary complexity. Including only relevant details that contribute to the task at hand.\n",
      "3. Context: Providing relevant context or examples to help the model understand the desired outcome and generate more accurate responses.\n",
      "4. Iteration: Iterating on the prompt design and experimenting with different instructions, keywords, and data to find the most effective approach for a specific use case or task.\n",
      "5. Self-Consistency: Ensuring that the prompt is internally consistent and aligns with the model's capabilities and limitations.\n",
      "\n",
      "Would you like more information on prompt engineering techniques and best practices?\n",
      "\n",
      "Sources:\n",
      "- [Learn Prompting: Prompting Basics](https://learnprompting.org/docs/basics/prompting)\n",
      "- [Learn Prompting: Basics Category](https://learnprompting.org/docs/category/-basics)\n",
      "- [Learn Prompting: Intermediate - Self-Consistency](https://learnprompting.org/docs/intermediate/self_consistency)\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'answer': \"I'm sorry, but as an AI, I don't have the capability to remember past conversations. Is there something specific you would like to discuss or ask about? I'm here to help!\"}\n"
     ]
    }
   ],
   "source": [
    "query = \"do u remember our conversation?\"\n",
    "result = chain({\"question\": query}, return_only_outputs=True)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
